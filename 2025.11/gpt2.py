#!/usr/bin/env python3
"""
GPT-2 Web GUI ç‰ˆæœ¬ (ä½¿ç”¨ Gradio)
ä½¿ç”¨æ–¹æ³•ï¼š
    pip install gradio
    python gpt2_web.py
"""

import torch
from transformers import GPT2LMHeadModel, GPT2Tokenizer
import gradio as gr


class GPT2WebApp:
    def __init__(self, model_name='gpt2'):
        print(f"ğŸ”„ åŠ è½½æ¨¡å‹: {model_name}...")
        self.tokenizer = GPT2Tokenizer.from_pretrained(model_name)
        self.model = GPT2LMHeadModel.from_pretrained(model_name)
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        self.model.to(self.device)
        self.model.eval()
        self.tokenizer.pad_token = self.tokenizer.eos_token
        print(f"âœ… æ¨¡å‹å·²åŠ è½½åˆ° {self.device}")

    def generate(self,
                 prompt,
                 max_length,
                 temperature,
                 top_k,
                 top_p,
                 num_sequences,
                 repetition_penalty,
                 use_sampling):
        """ç”Ÿæˆæ–‡æœ¬"""
        if not prompt.strip():
            return "âš ï¸ è¯·è¾“å…¥ Promptï¼"

        try:
            input_ids = self.tokenizer.encode(prompt, return_tensors='pt').to(self.device)

            with torch.no_grad():
                outputs = self.model.generate(
                    input_ids=input_ids,
                    max_length=max_length,
                    temperature=temperature if use_sampling else 1.0,
                    top_k=top_k,
                    top_p=top_p,
                    num_return_sequences=num_sequences,
                    repetition_penalty=repetition_penalty,
                    do_sample=use_sampling,
                    pad_token_id=self.tokenizer.eos_token_id,
                    eos_token_id=self.tokenizer.eos_token_id
                )

            results = []
            for i, output in enumerate(outputs, 1):
                text = self.tokenizer.decode(output, skip_special_tokens=True)
                results.append(f"{'=' * 70}\nã€ç”Ÿæˆ {i}ã€‘\n{'=' * 70}\n{text}\n")

            return "\n".join(results)

        except Exception as e:
            return f"âŒ é”™è¯¯: {str(e)}"


# åˆ›å»ºåº”ç”¨
app = GPT2WebApp('gpt2')

# åˆ›å»º Gradio ç•Œé¢
with gr.Blocks(title="GPT-2 æ–‡æœ¬ç”Ÿæˆå™¨", theme=gr.themes.Soft()) as demo:
    gr.Markdown("""
    # ğŸ¤– GPT-2 æ–‡æœ¬ç”Ÿæˆå™¨

    è¾“å…¥æç¤ºæ–‡æœ¬ï¼ˆPromptï¼‰ï¼Œè°ƒæ•´å‚æ•°ï¼Œç‚¹å‡»"ç”Ÿæˆ"æŒ‰é’®å¼€å§‹åˆ›ä½œï¼
    """)

    with gr.Row():
        with gr.Column(scale=1):
            # è¾“å…¥åŒºåŸŸ
            prompt_input = gr.Textbox(
                label="ğŸ“ è¾“å…¥ Prompt",
                placeholder="Once upon a time...",
                lines=5
            )

            generate_btn = gr.Button("ğŸš€ ç”Ÿæˆæ–‡æœ¬", variant="primary", size="lg")

            gr.Markdown("---")
            gr.Markdown("### âš™ï¸ ç”Ÿæˆå‚æ•°")

            # åŸºç¡€å‚æ•°
            with gr.Accordion("åŸºç¡€å‚æ•°", open=True):
                max_length = gr.Slider(
                    minimum=20,
                    maximum=500,
                    value=100,
                    step=10,
                    label="ğŸ“ æœ€å¤§é•¿åº¦ (max_length)",
                    info="ç”Ÿæˆæ–‡æœ¬çš„æœ€å¤§tokenæ•°é‡"
                )

                num_sequences = gr.Slider(
                    minimum=1,
                    maximum=5,
                    value=1,
                    step=1,
                    label="ğŸ”¢ ç”Ÿæˆæ•°é‡ (num_sequences)",
                    info="ç”Ÿæˆå‡ ä¸ªä¸åŒçš„ç‰ˆæœ¬"
                )

            # é‡‡æ ·å‚æ•°
            with gr.Accordion("é‡‡æ ·å‚æ•°", open=True):
                temperature = gr.Slider(
                    minimum=0.1,
                    maximum=2.0,
                    value=0.8,
                    step=0.1,
                    label="ğŸŒ¡ï¸ æ¸©åº¦ (temperature)",
                    info="æ§åˆ¶éšæœºæ€§ï¼šè¶Šä½è¶Šä¿å®ˆï¼Œè¶Šé«˜è¶Šåˆ›æ„"
                )

                top_k = gr.Slider(
                    minimum=10,
                    maximum=100,
                    value=50,
                    step=5,
                    label="ğŸ¯ Top-K",
                    info="ä»æ¦‚ç‡æœ€é«˜çš„Kä¸ªè¯ä¸­é‡‡æ ·"
                )

                top_p = gr.Slider(
                    minimum=0.5,
                    maximum=1.0,
                    value=0.95,
                    step=0.05,
                    label="ğŸ² Top-P (Nucleus)",
                    info="ä»ç´¯ç§¯æ¦‚ç‡è¾¾åˆ°Pçš„è¯ä¸­é‡‡æ ·"
                )

            # é«˜çº§å‚æ•°
            with gr.Accordion("é«˜çº§å‚æ•°", open=False):
                repetition_penalty = gr.Slider(
                    minimum=1.0,
                    maximum=2.0,
                    value=1.0,
                    step=0.1,
                    label="ğŸ” é‡å¤æƒ©ç½š (repetition_penalty)",
                    info="é¿å…é‡å¤ï¼š1.0 = ä¸æƒ©ç½šï¼Œè¶Šå¤§æƒ©ç½šè¶Šé‡"
                )

                use_sampling = gr.Checkbox(
                    value=True,
                    label="ğŸ° å¯ç”¨é‡‡æ · (do_sample)",
                    info="ç¦ç”¨åˆ™ä½¿ç”¨è´ªå¿ƒè§£ç ï¼ˆç¡®å®šæ€§è¾“å‡ºï¼‰"
                )

            # é¢„è®¾é…ç½®
            gr.Markdown("---")
            gr.Markdown("### ğŸ¨ å¿«é€Ÿé¢„è®¾")

            with gr.Row():
                preset_creative = gr.Button("âœï¸ åˆ›æ„å†™ä½œ", size="sm")
                preset_factual = gr.Button("ğŸ“° äº‹å®é™ˆè¿°", size="sm")
                preset_code = gr.Button("ğŸ’» ä»£ç ç”Ÿæˆ", size="sm")

        with gr.Column(scale=1):
            # è¾“å‡ºåŒºåŸŸ
            output_text = gr.Textbox(
                label="âœ¨ ç”Ÿæˆç»“æœ",
                lines=25,
                max_lines=30
            )

    # ç¤ºä¾‹
    gr.Markdown("---")
    gr.Markdown("### ğŸ’¡ ç¤ºä¾‹ Prompt")

    gr.Examples(
        examples=[
            ["Once upon a time in a magical forest", 100, 1.0, 50, 0.95, 2],
            ["The future of artificial intelligence is", 120, 0.8, 50, 0.9, 3],
            ["In a world where technology has advanced beyond imagination", 150, 1.2, 50, 0.95, 2],
            ["The secret to happiness is", 80, 0.7, 40, 0.9, 3],
            ["def calculate_fibonacci(n):", 100, 0.3, 30, 0.85, 1],
        ],
        inputs=[prompt_input, max_length, temperature, top_k, top_p, num_sequences],
        label="ç‚¹å‡»ç¤ºä¾‹å¿«é€Ÿå¼€å§‹"
    )

    # ç»‘å®šç”ŸæˆæŒ‰é’®
    generate_btn.click(
        fn=app.generate,
        inputs=[
            prompt_input,
            max_length,
            temperature,
            top_k,
            top_p,
            num_sequences,
            repetition_penalty,
            use_sampling
        ],
        outputs=output_text
    )


    # é¢„è®¾æŒ‰é’®åŠŸèƒ½
    def apply_creative_preset():
        return 1.2, 50, 0.95, 1.2, True


    def apply_factual_preset():
        return 0.7, 40, 0.9, 1.0, True


    def apply_code_preset():
        return 0.3, 30, 0.85, 1.0, True


    preset_creative.click(
        fn=apply_creative_preset,
        outputs=[temperature, top_k, top_p, repetition_penalty, use_sampling]
    )

    preset_factual.click(
        fn=apply_factual_preset,
        outputs=[temperature, top_k, top_p, repetition_penalty, use_sampling]
    )

    preset_code.click(
        fn=apply_code_preset,
        outputs=[temperature, top_k, top_p, repetition_penalty, use_sampling]
    )

    # ä½¿ç”¨è¯´æ˜
    with gr.Accordion("ğŸ“– ä½¿ç”¨è¯´æ˜", open=False):
        gr.Markdown("""
        ## å‚æ•°è¯´æ˜

        ### ğŸŒ¡ï¸ Temperature (æ¸©åº¦)
        - **0.1-0.5**: ä¿å®ˆã€å¯é¢„æµ‹ï¼ˆé€‚åˆäº‹å®æ€§å†…å®¹ã€ä»£ç ï¼‰
        - **0.6-0.9**: å¹³è¡¡ã€è‡ªç„¶ï¼ˆé€‚åˆä¸€èˆ¬å†™ä½œï¼‰
        - **1.0-1.5**: åˆ›æ„ã€éšæœºï¼ˆé€‚åˆåˆ›æ„å†™ä½œã€å¤´è„‘é£æš´ï¼‰
        - **1.5+**: æåº¦éšæœºï¼ˆå®éªŒæ€§ï¼‰

        ### ğŸ¯ Top-K
        - ä»æ¦‚ç‡æœ€é«˜çš„ K ä¸ªè¯ä¸­éšæœºé€‰æ‹©
        - è¶Šå°è¶Šä¿å®ˆï¼Œè¶Šå¤§è¶Šå¤šæ ·

        ### ğŸ² Top-P (Nucleus Sampling)
        - ä»ç´¯ç§¯æ¦‚ç‡è¾¾åˆ° P çš„è¯ä¸­é€‰æ‹©
        - 0.9-0.95 æ˜¯å¸¸ç”¨å€¼

        ### ğŸ” Repetition Penalty
        - 1.0 = ä¸æƒ©ç½šé‡å¤
        - 1.2-1.5 = è½»åº¦æƒ©ç½šï¼ˆæ¨èï¼‰
        - 2.0 = å¼ºåŠ›æƒ©ç½š

        ### ğŸ’¡ ä½¿ç”¨æŠ€å·§
        - åˆ›æ„å†™ä½œï¼šé«˜æ¸©åº¦ + é«˜ Top-P
        - äº‹å®é™ˆè¿°ï¼šä½æ¸©åº¦ + ä½ Top-K
        - ä»£ç ç”Ÿæˆï¼šæä½æ¸©åº¦ + ç¦ç”¨é‡‡æ ·
        """)

# å¯åŠ¨åº”ç”¨
if __name__ == "__main__":
    print("\n" + "=" * 70)
    print("ğŸš€ å¯åŠ¨ Web ç•Œé¢...")
    print("=" * 70)
    demo.launch(
        share=False,  # è®¾ä¸º True å¯ç”Ÿæˆå…¬å¼€é“¾æ¥
        server_name="0.0.0.0",
        server_port=7860
    )