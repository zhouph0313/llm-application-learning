Huggingfaceä½¿ç”¨æ•™ç¨‹ï¼Œpytorchç‰ˆæœ¬éƒ½å¯ä»¥ä½¿ç”¨ï¼Œä¸»è¦ç”¨äºä¸‹è½½å¯¹åº”çš„æ¨¡å‹è¿›è¡Œè°ƒç”¨
pipeline()ï¼šåˆ©ç”¨é¢„è®­ç»ƒæ¨¡å‹è¿›è¡Œæ¨ç†çš„æœ€ç®€å•æ–¹å¼

ä¾‹å­ï¼špipeline(task=â€œsentiment-analysisâ€)ï¼Œæƒ…æ„Ÿåˆ†æä»»åŠ¡

# äº¤äº’å¼ GPT-2 æ–‡æœ¬ç”Ÿæˆå™¨

ä»¥ä¸‹æ˜¯ä¸€ä¸ªå¸¦äº¤äº’å¼ç•Œé¢çš„ GPT-2 æ–‡æœ¬ç”Ÿæˆç±»ï¼Œæ”¯æŒè‡ªå®šä¹‰ç”Ÿæˆå‚æ•°ï¼ˆæ¸©åº¦ã€Top-K ç­‰ï¼‰ã€å¤šè½®ç”Ÿæˆå’Œå‚æ•°åŠ¨æ€ä¿®æ”¹ï¼š

```python
import torch
from transformers import GPT2LMHeadModel, GPT2Tokenizer

class InteractiveGPT2:
    def __init__(self, model_name='gpt2'):
        print("ğŸš€ åŠ è½½ GPT-2 æ¨¡å‹...")
        self.tokenizer = GPT2Tokenizer.from_pretrained(model_name)
        self.model = GPT2LMHeadModel.from_pretrained(model_name)
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        self.model.to(self.device)
        self.model.eval()
        self.tokenizer.pad_token = self.tokenizer.eos_token
        print(f"âœ… æ¨¡å‹å·²åŠ è½½åˆ° {self.device}\n")
    
    def generate(self, prompt, **kwargs):
        """ç”Ÿæˆæ–‡æœ¬"""
        input_ids = self.tokenizer.encode(prompt, return_tensors='pt').to(self.device)
        
        with torch.no_grad():
            output = self.model.generate(
                input_ids=input_ids,
                pad_token_id=self.tokenizer.eos_token_id,
                **kwargs
            )
        
        return self.tokenizer.decode(output[0], skip_special_tokens=True)
    
    def run(self):
        """è¿è¡Œäº¤äº’å¼ç•Œé¢"""
        print("=" * 70)
        print("ğŸ¤– GPT-2 æ–‡æœ¬ç”Ÿæˆå™¨")
        print("=" * 70)
        print("\næŒ‡ä»¤:")
        print("  - è¾“å…¥æ–‡æœ¬å¼€å§‹ç”Ÿæˆ")
        print("  - è¾“å…¥ 'settings' ä¿®æ”¹å‚æ•°")
        print("  - è¾“å…¥ 'quit' é€€å‡º")
        print("\né»˜è®¤å‚æ•°:")
        
        # é»˜è®¤å‚æ•°
        params = {
            'max_length': 100,
            'temperature': 0.8,
            'top_k': 50,
            'top_p': 0.95,
            'num_return_sequences': 1,
            'do_sample': True
        }
        
        for key, value in params.items():
            print(f"  {key}: {value}")
        print()
        
        while True:
            try:
                user_input = input("\nğŸ’¬ è¾“å…¥ Prompt (æˆ–æŒ‡ä»¤): ").strip()
                
                if not user_input:
                    continue
                
                if user_input.lower() == 'quit':
                    print("ğŸ‘‹ å†è§ï¼")
                    break
                
                if user_input.lower() == 'settings':
                    print("\nâš™ï¸  å½“å‰å‚æ•°:")
                    for key, value in params.items():
                        print(f"  {key}: {value}")
                    
                    print("\nä¿®æ”¹å‚æ•° (ç›´æ¥å›è½¦ä¿æŒä¸å˜):")
                    for key in params.keys():
                        new_value = input(f"  {key} [{params[key]}]: ").strip()
                        if new_value:
                            try:
                                if key == 'do_sample':
                                    params[key] = new_value.lower() == 'true'
                                elif key == 'num_return_sequences':
                                    params[key] = int(new_value)
                                elif key == 'max_length' or key == 'top_k':
                                    params[key] = int(new_value)
                                else:
                                    params[key] = float(new_value)
                            except:
                                print(f"  âš ï¸  æ— æ•ˆå€¼ï¼Œä¿æŒ {key}={params[key]}")
                    continue
                
                # ç”Ÿæˆæ–‡æœ¬
                print("\nğŸ”„ ç”Ÿæˆä¸­...")
                
                for i in range(params['num_return_sequences']):
                    result = self.generate(user_input, **params)
                    print(f"\nğŸ“ ç”Ÿæˆ {i+1}:")
                    print("-" * 70)
                    print(result)
                    print("-" * 70)
            
            except KeyboardInterrupt:
                print("\n\nğŸ‘‹ å†è§ï¼")
                break
            except Exception as e:
                print(f"\nâŒ é”™è¯¯: {e}")

if __name__ == "__main__":
    generator = InteractiveGPT2('gpt2')
    generator.run()
```

å­¦ä¹ äº†å¦‚ä½•ä½¿ç”¨huggingfaceçš„æ¨¡å‹ç®€å•è°ƒç”¨ï¼Œå®ç°å¦‚æƒ…æ„Ÿåˆ†ç±»ï¼Œæ–‡æœ¬ç”Ÿæˆç­‰æ•ˆæœï¼Œè¿˜éœ€å›é¡¾ç›¸å…³ä»£ç ï¼Œç½‘å€ä¸­æœ‰ç›¸åº”çš„è¿›é˜¶æ•™ç¨‹ï¼Œå¦‚å¾®è°ƒç­‰æŠ€æœ¯ï¼Œéœ€è¦ä»”ç»†é˜…è¯»ä»£ç å­¦ä¹ 

gpt2.pyå®ç°äº†ä¸€ä¸ªç½‘ç«™å½¢å¼çš„è‡ªåŠ¨åŒ–è„šæœ¬è¿è¡Œï¼Œå¯ä»¥è¾“å…¥ç›¸åº”å†…å®¹è¿›è¡Œè¾“å‡ºï¼Œå¯ä»¥çœ‹ä½œä¸€ä¸ªç®€å•çš„demoå­¦ä¹ ã€‚
